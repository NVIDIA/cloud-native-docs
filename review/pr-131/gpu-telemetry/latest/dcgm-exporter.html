<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DCGM Exporter &mdash; NVIDIA GPU Telemetry 1.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="_static/api-styles.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/mermaid-init.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/design-tabs.js"></script>
        <script src="_static/version.js"></script>
        <script src="_static/social-media.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Integrating GPU Telemetry into Kubernetes" href="integrating-telemetry-kubernetes.html" />
    <link rel="prev" title="About GPU Telemetry" href="about-telemetry.html" />
 
<script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
          </a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">DCGM Exporter</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about-telemetry.html">About GPU Telemetry</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">DCGM Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="integrating-telemetry-kubernetes.html">Integrating GPU Telemetry into Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="kube-prometheus.html">Setting up Prometheus</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NVIDIA GPU Telemetry</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
<div> <!-- class="omni-version-warning" -->
  <p class="omni-version-warning-content"> Upgrade to NVIDIA Container Toolkit v1.16.2 or GPU Operator v24.6.2 to install a critical security update.<br/>
  Refer to <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5582">Security Bulletin: NVIDIA Container Toolkit - September 2024</a> for more information.</p>
</div>

<li>
    <a href="https://docs.nvidia.com">NVIDIA Docs Hub</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>
    <a href="https://docs.nvidia.com/datacenter/cloud-native/">NVIDIA Cloud Native Technologies</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>DCGM Exporter</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="dcgm-exporter">
<h1>DCGM Exporter<a class="headerlink" href="#dcgm-exporter" title="Permalink to this headline"></a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#introduction" id="id1">Introduction</a></p></li>
<li><p><a class="reference internal" href="#running-dcgm-exporter" id="id2">Running DCGM Exporter</a></p></li>
<li><p><a class="reference internal" href="#dcgm-exporter-customization" id="id3">DCGM-Exporter Customization</a></p>
<ul>
<li><p><a class="reference internal" href="#connecting-to-an-existing-dcgm-agent" id="id4">Connecting to an existing DCGM agent</a></p></li>
<li><p><a class="reference internal" href="#connecting-to-a-dcgm-standalone-container" id="id5">Connecting to a DCGM standalone container</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#multi-instance-gpu-mig-support" id="id6">Multi-Instance GPU (MIG) Support</a></p></li>
</ul>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://github.com/NVIDIA/dcgm-exporter">DCGM-Exporter</a> is a tool based on the
Go APIs to <a class="reference external" href="https://developer.nvidia.com/dcgm">NVIDIA DCGM</a> that allows users to gather
GPU metrics and understand workload behavior or monitor GPUs in clusters. DCGM Exporter is
written in Go and exposes GPU metrics at an HTTP endpoint (<code class="docutils literal notranslate"><span class="pre">/metrics</span></code>) for monitoring solutions
such as Prometheus.</p>
<p>For information on the profiling metrics available from DCGM, refer to
<a class="reference external" href="https://docs.nvidia.com/datacenter/dcgm/latest/dcgm-api/dcgm-api-profiling.html#profiling" title="(in NVIDIA DCGM Documentation vVersion: 3.3 (Latest))"><span>Profiling</span></a> in the DCGM documentation.</p>
<p>You can run DCGM Exporter as a standalone container or deployed as a
daemonset on GPU nodes in a Kubernetes cluster.</p>
<p>Because DCGM Exporter starts <cite>nv-hostengine</cite> as an embedded process (for collecting metrics),
appropriate configuration options should be used if DCGM Exporter is run on systems (such as
NVIDIA DGX) that have DCGM (or rather <cite>nv-hostengine</cite>) running.</p>
</section>
<section id="running-dcgm-exporter">
<h2>Running DCGM Exporter<a class="headerlink" href="#running-dcgm-exporter" title="Permalink to this headline"></a></h2>
<p>The DCGM Exporter container can be run using a container engine such as Docker. In this mode, DCGM Exporter
starts <cite>nv-hostengine</cite> as an embedded process and starts publishing metrics:</p>
<a class="reference internal image-reference" href="_images/dcgm-exporter_embedded.png"><img alt="_images/dcgm-exporter_embedded.png" src="_images/dcgm-exporter_embedded.png" style="width: 800px;" /></a>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.1.4-2.3.1 <span class="o">&amp;&amp;</span> <span class="se">\</span>
docker run -d --rm <span class="se">\</span>
   --gpus all <span class="se">\</span>
   --net host <span class="se">\</span>
   --cap-add SYS_ADMIN <span class="se">\</span>
   nvcr.io/nvidia/k8s/dcgm-exporter:<span class="si">${</span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="si">}</span>-ubuntu20.04 <span class="se">\</span>
   -f /etc/dcgm-exporter/dcp-metrics-included.csv
</pre></div>
</div>
<p>Retrieve the metrics:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl localhost:9400/metrics
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>HELP DCGM_FI_DEV_SM_CLOCK SM clock frequency <span class="o">(</span><span class="k">in</span> MHz<span class="o">)</span>.
<span class="gp"># </span>TYPE DCGM_FI_DEV_SM_CLOCK gauge
<span class="gp"># </span>HELP DCGM_FI_DEV_MEM_CLOCK Memory clock frequency <span class="o">(</span><span class="k">in</span> MHz<span class="o">)</span>.
<span class="gp"># </span>TYPE DCGM_FI_DEV_MEM_CLOCK gauge
<span class="gp"># </span>HELP DCGM_FI_DEV_MEMORY_TEMP Memory temperature <span class="o">(</span><span class="k">in</span> C<span class="o">)</span>.
<span class="gp"># </span>TYPE DCGM_FI_DEV_MEMORY_TEMP gauge
<span class="go">...</span>
<span class="go">DCGM_FI_DEV_SM_CLOCK{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 139</span>
<span class="go">DCGM_FI_DEV_MEM_CLOCK{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 405</span>
<span class="go">DCGM_FI_DEV_MEMORY_TEMP{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 9223372036854775794</span>
<span class="go">...</span>
</pre></div>
</div>
</section>
<section id="dcgm-exporter-customization">
<h2>DCGM-Exporter Customization<a class="headerlink" href="#dcgm-exporter-customization" title="Permalink to this headline"></a></h2>
<p>DCGM-Exporter has various options for adjusting its default behavior. Each option supports both a command-line flag and environment variable.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 20%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Environment Variable</p></th>
<th class="head"><p>Command-Line Flag</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_COLLECTORS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-f</span></code></p></td>
<td><p>File Path</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Path to file containing DCGM fields to collect. Default: “/etc/dcgm-exporter/default-counters.csv”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_LISTEN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-a</span></code></p></td>
<td><p>Address</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Address of listening http server. Default: “:9400”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_INTERVAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-c</span></code></p></td>
<td><p>Interval</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Interval of time at which point metrics are collected. Unit is milliseconds. Default:30000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_KUBERNETES</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-k</span></code></p></td>
<td><p>Boolean</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Enable kubernetes mapping metrics to kubernetes pods. Default: false</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_CONFIGMAP_DATA</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-m</span></code></p></td>
<td><p>Namespace:Name</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>ConfigMap namespace and name containing DCGM fields to collect. Default: “none”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_REMOTE_HOSTENGINE_INFO</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-r</span></code></p></td>
<td><p>Host:Port</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Connect to remote hostengine at Host:Port. Default: NA (dcgm-exporter will started  in embedded mode)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_DEVICES_STR</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-d</span></code></p></td>
<td><p>Device String (see following note)</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Specify which devices to monitor. Default: all GPU instances in MIG mode, all GPUs if MIG disabled.</p></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Device String Syntax: <code class="docutils literal notranslate"><span class="pre">[f]</span> <span class="pre">|</span> <span class="pre">[g[:id1[,-id2]]]</span> <span class="pre">|</span> <span class="pre">[i[:id1[,-id2]]]</span></code></p>
<p>If an id list is used, then devices with matching IDs must exist on the system. For example:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f</span></code> = Monitor all GPUs if MIG is disabled, or all GPU instances if MIG is enabled</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">g</span></code> = Monitor all GPUs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i</span></code> = Monitor all GPU instances</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">g:0,1</span></code> = monitor GPUs 0 and 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i:0,2-4</span></code> = monitor GPU instances 0, 2, 3, and 4.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span></code> cannot be specified unless MIG mode is enabled.</p></li>
<li><p>Any time indices are specified, those indices must exist on the system.</p></li>
<li><p>In MIG mode, only <code class="docutils literal notranslate"><span class="pre">f</span></code> or <code class="docutils literal notranslate"><span class="pre">i</span></code> with a range can be specified. GPUs are not assigned to pods and therefore reporting must occur at the GPU instance level. (default: <code class="docutils literal notranslate"><span class="pre">f</span></code>)</p></li>
</ol>
</div>
<section id="connecting-to-an-existing-dcgm-agent">
<h3>Connecting to an existing DCGM agent<a class="headerlink" href="#connecting-to-an-existing-dcgm-agent" title="Permalink to this headline"></a></h3>
<p>In this scenario, system images include DCGM and have <cite>nv-hostengine</cite> running already. Examples include
the DGX systems that bundles drivers, DCGM, etc. in the system image. To avoid any compatibility issues,
it is recommended to have DCGM Exporter connect to the existing <cite>nv-hostengine</cite> daemon to gather/publish
GPU telemetry data.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The DCGM Exporter container image includes a DCGM client library (<code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) to communicate with
<cite>nv-hostengine</cite>. In this deployment scenario we have DCGM Exporter (or rather <code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) connect
to an existing <cite>nv-hostengine</cite> running on the host. The DCGM client library uses an internal protocol to exchange
information with <cite>nv-hostengine</cite>. To avoid any potential incompatibilities between the container image’s DCGM client library
and the host’s <cite>nv-hostengine</cite>, it is strongly recommended to use a version of DCGM on which DCGM Exporter is based is
greater than or equal to (but not less than) the version of DCGM running on the host. This can be easily determined by
comparing the version tags of the DCGM Exporter image and by running <code class="docutils literal notranslate"><span class="pre">nv-hostengine</span> <span class="pre">--version</span></code> on the host.</p>
</div>
<p>In this scenario, we use the <code class="docutils literal notranslate"><span class="pre">-r</span></code> option to connect to an existing <cite>nv-hostengine</cite> process:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.1.4-2.3.1 <span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --net host \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   nvcr.io/nvidia/k8s/dcgm-exporter:${DCGM_EXPORTER_VERSION}-ubuntu20.04 \</span>
<span class="go">   -r localhost:5555 -f /etc/dcgm-exporter/dcp-metrics-included.csv</span>
</pre></div>
</div>
</section>
<section id="connecting-to-a-dcgm-standalone-container">
<h3>Connecting to a DCGM standalone container<a class="headerlink" href="#connecting-to-a-dcgm-standalone-container" title="Permalink to this headline"></a></h3>
<p>In this scenario the DCGM <cite>nv-hostengine</cite> runs in a separate container on the same host making its client port available to
DCGM-Exporter as well as dcgmi client commands.</p>
<a class="reference internal image-reference" href="_images/dcgm_and_dcgm-exporter.png"><img alt="_images/dcgm_and_dcgm-exporter.png" src="_images/dcgm_and_dcgm-exporter.png" style="width: 800px;" /></a>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Similar to the warning when connecting to an existing DCGM agent, the DCGM Exporter container image includes a
DCGM client library (<code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) to communicate with <cite>nv-hostengine</cite> running in a separate container.
The DCGM client library in use by DCGM-Exporter uses an internal protocol to exchange information with <cite>nv-hostengine</cite>.
To avoid any potential incompatibilities between the container image’s DCGM client library
and the standalone DCGM container’s <cite>nv-hostengine</cite>, it is strongly recommended to ensure the version of DCGM on which
DCGM Exporter is based is greater than or equal to (but not less than) the version of DCGM running in the standalone
container. This can be easily determined by comparing the version tags of the DCGM Exporter and <cite>dcgm</cite> standalone image.</p>
</div>
<p>First, start the standalone DCGM container with the <cite>nv-hostengine</cite> port available to external applications:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$</span><span class="nv">DCGM_VERSION</span><span class="o">=</span><span class="m">2</span>.2.9 <span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   -p 5555:5555 \</span>
<span class="go">   nvidia/dcgm:${DCGM_VERSION}-ubuntu20.04</span>
</pre></div>
</div>
<p>Second, start the dcgm-exporter container with <code class="docutils literal notranslate"><span class="pre">r</span></code> option to connect to an existing <cite>nv-hostengine</cite> port:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$</span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.2.9-2.5.0 <span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --net host \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   nvcr.io/nvidia/k8s/dcgm-exporter:${DCGM_EXPORTER_VERSION}-ubuntu20.04 \</span>
<span class="go">   -r localhost:5555 -f /etc/dcgm-exporter/dcp-metrics-included.csv</span>
</pre></div>
</div>
<p>In this scenario <cite>dcgmi</cite> commands run on the host will also connect to the <cite>nv-hostengine</cite> running in the standalone
DCGM container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">dcgmi discovery -l</span>
<span class="go">1 GPU found.</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
<span class="go">| GPU ID | Device Information                                                   |</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
<span class="go">| 0      | Name: Quadro RTX 6000                                                |</span>
<span class="go">|        | PCI Bus ID: 00000000:65:00.0                                         |</span>
<span class="go">|        | Device UUID: GPU-2f6576bf-3c29-1fbb-068d-e74c4a97f0c5                |</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
</pre></div>
</div>
</section>
</section>
<section id="multi-instance-gpu-mig-support">
<h2>Multi-Instance GPU (MIG) Support<a class="headerlink" href="#multi-instance-gpu-mig-support" title="Permalink to this headline"></a></h2>
<p>The new Multi-Instance GPU (MIG) feature allows the GPUs based on the NVIDIA Ampere architecture to be
securely partitioned into up to seven separate GPU Instances for CUDA applications, providing multiple users
with separate GPU resources for optimal GPU utilization.</p>
<p>For more information on MIG, refer to the MIG <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">User Guide</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Support for MIG in DCGM Exporter was added starting with <code class="docutils literal notranslate"><span class="pre">2.4.0-rc.2</span></code>. Replace the container image with this tag in the
command line examples above: <code class="docutils literal notranslate"><span class="pre">2.1.8-2.4.0-rc.2-ubuntu20.04</span></code>. If you are connecting to an existing DCGM on the host system,
ensure that you upgrade to at least 2.1.8 on the host system.</p>
</div>
<p>DCGM Exporter publishes metrics for both the entire GPU as well as individual MIG devices (or GPU instances)
as can be seen in the output below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">DCGM_FI_DEV_SM_CLOCK{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 1215</span>
<span class="go">DCGM_FI_DEV_MEM_CLOCK{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 1215</span>
<span class="go">DCGM_FI_DEV_MEMORY_TEMP{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 69</span>
<span class="go">DCGM_FI_DEV_GPU_TEMP{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 61</span>
<span class="go">DCGM_FI_DEV_POWER_USAGE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 409.692000</span>
<span class="go">DCGM_FI_DEV_TOTAL_ENERGY_CONSUMPTION{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 319159391</span>
<span class="go">DCGM_FI_DEV_PCIE_REPLAY_COUNTER{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_XID_ERRORS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_FB_FREE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 35690</span>
<span class="go">DCGM_FI_DEV_FB_USED{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 4845</span>
<span class="go">DCGM_FI_DEV_NVLINK_BANDWIDTH_TOTAL{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_VGPU_LICENSE_STATUS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_PROF_GR_ENGINE_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.995630</span>
<span class="go">DCGM_FI_PROF_PIPE_TENSOR_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.929260</span>
<span class="go">DCGM_FI_PROF_DRAM_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.690789</span>
<span class="go">DCGM_FI_PROF_PCIE_TX_BYTES{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 33011804</span>
<span class="go">DCGM_FI_PROF_PCIE_RX_BYTES{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 97863601</span>

<span class="go">DCGM_FI_DEV_XID_ERRORS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_PROF_GR_ENGINE_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.995687</span>
<span class="go">DCGM_FI_PROF_PIPE_TENSOR_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.930433</span>
<span class="go">DCGM_FI_PROF_DRAM_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.800339</span>
</pre></div>
</div>
<p>For more information on the profiling metrics and how to interpret the metrics, refer to the <a class="reference external" href="https://docs.nvidia.com/datacenter/dcgm/latest/dcgm-user-guide/feature-overview.html#profiling">profiling metrics</a>
section of the DCGM user guide.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="about-telemetry.html" class="btn btn-neutral float-left" title="About GPU Telemetry" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="integrating-telemetry-kubernetes.html" class="btn btn-neutral float-right" title="Integrating GPU Telemetry into Kubernetes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
<img src="_static/NVIDIA-LogoBlack.svg" class="only-light"/>
<img src="_static/NVIDIA-LogoWhite.svg" class="only-dark"/>
<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>
<p>
  Copyright &#169; 2020-2024, NVIDIA Corporation.
</p>

    <p>
      <span class="lastupdated">Last updated on Nov 21, 2024.
      </span></p>
<script type="text/javascript">if (typeof _satellite !== "undefined"){ _satellite.pageBottom();}</script>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>