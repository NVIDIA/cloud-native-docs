<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Installing the NVIDIA GPU Operator on OpenShift &mdash; NVIDIA GPU Operator on Red Hat OpenShift Container Platform 24.6.2 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="_static/api-styles.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/mermaid-init.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/design-tabs.js"></script>
        <script src="_static/version.js"></script>
        <script src="_static/social-media.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="NVIDIA AI Enterprise with OpenShift" href="nvaie-with-ocp.html" />
    <link rel="prev" title="Installing the Node Feature Discovery Operator on OpenShift" href="install-nfd.html" />
 
<script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
          </a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="steps-overview.html">Installation and Upgrade Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-nfd.html">NFD Operator Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">GPU Operator Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nvaie-with-ocp.html">NVIDIA AI Enterprise with OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="mig-ocp.html">MIG Support in OpenShift Container Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="clean-up.html">Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="mirror-gpu-ocp-disconnected.html">Deploy GPU Operators in a disconnected or airgapped environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable-gpu-monitoring-dashboard.html">Enabling the GPU Monitoring Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable-gpu-monitoring-dashboard.html#viewing-gpu-metrics">Viewing GPU Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="time-slicing-gpus-in-openshift.html">Time-slicing NVIDIA GPUs in OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="openshift-virtualization.html">NVIDIA GPU Operator with OpenShift Virtualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-with-precompiled-drivers.html">Precompiled Drivers for the NVIDIA GPU Operator for RHCOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting-gpu-ocp.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-ocp.html">Appendix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NVIDIA GPU Operator on Red Hat OpenShift Container Platform</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
<div> <!-- class="omni-version-warning" -->
  <p class="omni-version-warning-content"> Upgrade to NVIDIA Container Toolkit v1.16.2 or GPU Operator v24.6.2 to install a critical security update.<br/>
  Refer to <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5582">Security Bulletin: NVIDIA Container Toolkit - September 2024</a> for more information.</p>
</div>

<li>
    <a href="https://docs.nvidia.com">NVIDIA Docs Hub</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>
    <a href="https://docs.nvidia.com/datacenter/cloud-native/">NVIDIA Cloud Native Technologies</a>
    <i class="fa fa-chevron-right" aria-hidden="true"></i>
</li>
<li>Installing the NVIDIA GPU Operator on OpenShift</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="installing-the-nvidia-gpu-operator-on-openshift">
<span id="install-nvidiagpu"></span><h1>Installing the NVIDIA GPU Operator on OpenShift<a class="headerlink" href="#installing-the-nvidia-gpu-operator-on-openshift" title="Permalink to this headline"></a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#installing-the-nvidia-gpu-operator-by-using-the-web-console" id="id3">Installing the NVIDIA GPU Operator by using the web console</a></p></li>
<li><p><a class="reference internal" href="#installing-the-nvidia-gpu-operator-using-the-cli" id="id4">Installing the NVIDIA GPU Operator using the CLI</a></p></li>
<li><p><a class="reference internal" href="#create-the-clusterpolicy-instance" id="id5">Create the ClusterPolicy instance</a></p>
<ul>
<li><p><a class="reference internal" href="#create-the-cluster-policy-using-the-web-console" id="id6">Create the cluster policy using the web console</a></p></li>
<li><p><a class="reference internal" href="#create-the-cluster-policy-using-the-cli" id="id7">Create the cluster policy using the CLI</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#create-the-clusterpolicy-instance-with-nvidia-vgpu" id="id8">Create the ClusterPolicy instance with NVIDIA vGPU</a></p>
<ul>
<li><p><a class="reference internal" href="#pre-requisites" id="id9">Pre-requisites</a></p></li>
<li><p><a class="reference internal" href="#id1" id="id10">Create the cluster policy using the web console</a></p></li>
<li><p><a class="reference internal" href="#id2" id="id11">Create the cluster policy using the CLI</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#verify-the-successful-installation-of-the-nvidia-gpu-operator" id="id12">Verify the successful installation of the NVIDIA GPU Operator</a></p></li>
<li><p><a class="reference internal" href="#cluster-monitoring" id="id13">Cluster monitoring</a></p></li>
<li><p><a class="reference internal" href="#logging" id="id14">Logging</a></p></li>
<li><p><a class="reference internal" href="#running-a-sample-gpu-application" id="id15">Running a sample GPU Application</a></p></li>
<li><p><a class="reference internal" href="#getting-information-about-the-gpu" id="id16">Getting information about the GPU</a></p></li>
</ul>
</div>
<section id="installing-the-nvidia-gpu-operator-by-using-the-web-console">
<h2>Installing the NVIDIA GPU Operator by using the web console<a class="headerlink" href="#installing-the-nvidia-gpu-operator-by-using-the-web-console" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>In the OpenShift Container Platform web console from the side menu, navigate to  <strong>Operators</strong> &gt; <strong>OperatorHub</strong> and select <strong>All Projects</strong>.</p></li>
<li><p>In <strong>Operators</strong> &gt; <strong>OperatorHub</strong>, search for the <strong>NVIDIA GPU Operator</strong>. For additional information see the <a class="reference external" href="https://docs.openshift.com/container-platform/latest/operators/admin/olm-adding-operators-to-cluster.html">Red Hat OpenShift Container Platform documentation</a>.</p></li>
<li><p>Select the <strong>NVIDIA GPU Operator</strong>, click <strong>Install</strong>. In the subsequent screen click <strong>Install</strong>.</p></li>
</ol>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here, you can select the namespace where you want to deploy the GPU Operator. The suggested namespace to use is the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code>. You can choose any existing namespace or create a new namespace under <strong>Select a Namespace</strong>.</p>
<p>If you install in any other namespace other than <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code>, the GPU Operator will <strong>not</strong> automatically enable namespace monitoring, and metrics and alerts will <strong>not</strong> be collected by Prometheus.
If only trusted operators are installed in this namespace, you can manually enable namespace monitoring with this command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc label ns/<span class="nv">$NAMESPACE_NAME</span> openshift.io/cluster-monitoring<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
</div>
</div></blockquote>
<p>Proceed to <a class="reference internal" href="#create-cluster-policy"><span class="std std-ref">Create the cluster policy for the NVIDIA GPU Operator</span></a>.</p>
</section>
<section id="installing-the-nvidia-gpu-operator-using-the-cli">
<h2>Installing the NVIDIA GPU Operator using the CLI<a class="headerlink" href="#installing-the-nvidia-gpu-operator-using-the-cli" title="Permalink to this headline"></a></h2>
<p>As a cluster administrator, you can install the <strong>NVIDIA GPU Operator</strong> using the OpenShift CLI (<code class="docutils literal notranslate"><span class="pre">oc</span></code>).</p>
<ol class="arabic">
<li><p>Create a namespace for the <strong>NVIDIA GPU Operator</strong>.</p>
<ol class="arabic">
<li><p>Create the following <code class="docutils literal notranslate"><span class="pre">Namespace</span></code> custom resource (CR) that defines the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code> namespace, and then save the YAML in the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator.yaml</span></code> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Namespace</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The suggested namespace to use is the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code>. You can choose any existing namespace or create a new namespace name.
If you install in any other namespace other than <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code>, the GPU Operator will <strong>not</strong> automatically enable namespace monitoring, and metrics and alerts will <strong>not</strong> be collected by Prometheus.</p>
<p>If only trusted operators are installed in this namespace, you can manually enable namespace monitoring with this command:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc label ns/<span class="nv">$NAMESPACE_NAME</span> openshift.io/cluster-monitoring<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
</div></blockquote>
</div>
</li>
<li><p>Create the namespace by running the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc create -f nvidia-gpu-operator.yaml
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">namespace/nvidia-gpu-operator created</span>
</pre></div>
</div>
</li>
</ol>
</li>
<li><p>Install the <strong>NVIDIA GPU Operator</strong> in the namespace you created in the previous step by creating the following objects:</p>
<ol class="arabic">
<li><p>Create the following <code class="docutils literal notranslate"><span class="pre">OperatorGroup</span></code> CR and save the YAML in the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operatorgroup.yaml</span></code> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">operators.coreos.com/v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OperatorGroup</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator-group</span><span class="w"></span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w"> </span><span class="nt">targetNamespaces</span><span class="p">:</span><span class="w"></span>
<span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Create the <code class="docutils literal notranslate"><span class="pre">OperatorGroup</span></code> CR by running the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc create -f nvidia-gpu-operatorgroup.yaml
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">operatorgroup.operators.coreos.com/nvidia-gpu-operator-group created</span>
</pre></div>
</div>
</li>
</ol>
</li>
<li><p>Run the following command to get the <code class="docutils literal notranslate"><span class="pre">channel</span></code> value required for step number 5.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get packagemanifest gpu-operator-certified -n openshift-marketplace -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.status.defaultChannel}&#39;</span>
</pre></div>
</div>
<p><strong>Example output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">v22.9</span>
</pre></div>
</div>
</li>
<li><p>Run the following commands to get the <code class="docutils literal notranslate"><span class="pre">startingCSV</span></code> value required for step number 5.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">CHANNEL</span><span class="o">=</span>v22.9
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get packagemanifests/gpu-operator-certified -n openshift-marketplace -ojson <span class="p">|</span> jq -r <span class="s1">&#39;.status.channels[] | select(.name == &quot;&#39;</span><span class="nv">$CHANNEL</span><span class="s1">&#39;&quot;) | .currentCSV&#39;</span>
</pre></div>
</div>
<p><strong>Example output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">gpu-operator-certified.v22.9.0</span>
</pre></div>
</div>
</li>
<li><p>Create the following <code class="docutils literal notranslate"><span class="pre">Subscription</span></code> CR and save the YAML in the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-sub.yaml</span></code> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">operators.coreos.com/v1alpha1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Subscription</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-operator-certified</span><span class="w"></span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">channel</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;v22.9&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">installPlanApproval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Manual</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-operator-certified</span><span class="w"></span>
<span class="w">  </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">certified-operators</span><span class="w"></span>
<span class="w">  </span><span class="nt">sourceNamespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">openshift-marketplace</span><span class="w"></span>
<span class="w">  </span><span class="nt">startingCSV</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;gpu-operator-certified.v22.9.0&quot;</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Update the <code class="docutils literal notranslate"><span class="pre">channel</span></code> and <code class="docutils literal notranslate"><span class="pre">startingCSV</span></code> fields with the information returned in step 3 and 4.</p>
</div>
</li>
<li><p>Create the subscription object by running the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc create -f nvidia-gpu-sub.yaml
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">subscription.operators.coreos.com/gpu-operator-certified created</span>
</pre></div>
</div>
</li>
<li><p>Optional: Log in to web console and navigate to the <strong>Operators</strong> &gt; <strong>Installed Operators</strong> page. In the <code class="docutils literal notranslate"><span class="pre">Project:</span> <span class="pre">nvidia-gpu-operator</span></code> the following is displayed:</p>
<img alt="_images/gpu-operator-certified-cli-install.png" src="_images/gpu-operator-certified-cli-install.png" />
</li>
<li><p>Verify an install plan has been created:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get installplan -n nvidia-gpu-operator
</pre></div>
</div>
<p><strong>Example output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME            CSV                              APPROVAL   APPROVED</span>
<span class="go">install-wwhfj   gpu-operator-certified.v22.9.0   Manual     false</span>
</pre></div>
</div>
</li>
<li><p>Approve the install plan using the CLI commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">INSTALL_PLAN</span><span class="o">=</span><span class="k">$(</span>oc get installplan -n nvidia-gpu-operator -oname<span class="k">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc patch <span class="nv">$INSTALL_PLAN</span> -n nvidia-gpu-operator --type merge --patch <span class="s1">&#39;{&quot;spec&quot;:{&quot;approved&quot;:true }}&#39;</span>
</pre></div>
</div>
<p><strong>Example output</strong></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">installplan.operators.coreos.com/install-wwhfj patched</span>
</pre></div>
</div>
</li>
<li><p>Alternatively click <code class="docutils literal notranslate"><span class="pre">Upgrade</span> <span class="pre">available</span></code> and approve the plan using the web console:</p>
<img alt="_images/gpu-operator-certified-cli-install.png" src="_images/gpu-operator-certified-cli-install.png" />
</li>
<li><p>Optional: Verify the successful install in the web console. The display changes to:</p>
<img alt="_images/cluster_policy_suceed.png" src="_images/cluster_policy_suceed.png" />
</li>
</ol>
</section>
<section id="create-the-clusterpolicy-instance">
<span id="create-cluster-policy"></span><h2>Create the ClusterPolicy instance<a class="headerlink" href="#create-the-clusterpolicy-instance" title="Permalink to this headline"></a></h2>
<p>When you install the <strong>NVIDIA GPU Operator</strong> in the OpenShift Container Platform, a custom resource definition for a ClusterPolicy is created. The ClusterPolicy configures the GPU stack, configuring the image names and repository, pod restrictions/credentials and so on.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you create a ClusterPolicy that contains an empty specification, such as <code class="docutils literal notranslate"><span class="pre">spec{}</span></code>, the ClusterPolicy fails to deploy.</p>
</div>
<p>As a cluster administrator, you can create a ClusterPolicy using the OpenShift Container Platform CLI or the web console. Also, these steps differ
when using <strong>NVIDIA vGPU</strong>. Please refer to appropriate sections below.</p>
<section id="create-the-cluster-policy-using-the-web-console">
<span id="create-cluster-policy-web-console"></span><h3>Create the cluster policy using the web console<a class="headerlink" href="#create-the-cluster-policy-using-the-web-console" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>In the OpenShift Container Platform web console, from the side menu, select <strong>Operators</strong> &gt; <strong>Installed Operators</strong>, and click <strong>NVIDIA GPU Operator</strong>.</p></li>
<li><p>Select the <strong>ClusterPolicy</strong> tab, then click <strong>Create ClusterPolicy</strong>. The platform assigns the default name <em>gpu-cluster-policy</em>.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can use this screen to customize the ClusterPolicy however the default are sufficient to get the GPU configured and running.</p>
</div>
</div></blockquote>
</li>
<li><p>Click <strong>Create</strong>.</p>
<p>At this point, the GPU Operator proceeds and installs all the required components to set up the NVIDIA GPUs in the OpenShift 4 cluster. Wait at least 10-20 minutes before digging deeper into any form of troubleshooting because this may take a period of time to finish.</p>
</li>
<li><p>The status of the newly deployed ClusterPolicy <em>gpu-cluster-policy</em> for the NVIDIA GPU Operator changes to <code class="docutils literal notranslate"><span class="pre">State:ready</span></code> when the installation succeeds.</p></li>
</ol>
<blockquote>
<div><img alt="_images/cluster-policy-state-ready.png" src="_images/cluster-policy-state-ready.png" />
</div></blockquote>
</section>
<section id="create-the-cluster-policy-using-the-cli">
<span id="verify-gpu-operator-install-ocp"></span><h3>Create the cluster policy using the CLI<a class="headerlink" href="#create-the-cluster-policy-using-the-cli" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create the ClusterPolicy:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get csv -n nvidia-gpu-operator gpu-operator-certified.v22.9.0 -ojsonpath<span class="o">={</span>.metadata.annotations.alm-examples<span class="o">}</span> <span class="p">|</span> jq .<span class="o">[</span><span class="m">0</span><span class="o">]</span> &gt; clusterpolicy.json
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc apply -f clusterpolicy.json
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">clusterpolicy.nvidia.com/gpu-cluster-policy created</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="create-the-clusterpolicy-instance-with-nvidia-vgpu">
<h2>Create the ClusterPolicy instance with NVIDIA vGPU<a class="headerlink" href="#create-the-clusterpolicy-instance-with-nvidia-vgpu" title="Permalink to this headline"></a></h2>
<section id="pre-requisites">
<h3>Pre-requisites<a class="headerlink" href="#pre-requisites" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Please refer to <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/install-gpu-operator-vgpu.html#install-gpu-operator-vgpu" title="(in NVIDIA GPU Operator)"><span>Using NVIDIA vGPU</span></a> section for pre-requisite steps for using NVIDIA vGPU on RedHat OpenShift.</p></li>
</ul>
</section>
<section id="id1">
<h3>Create the cluster policy using the web console<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<ol class="arabic simple">
<li><p>In the OpenShift Container Platform web console, from the side menu, select <strong>Operators</strong> &gt; <strong>Installed Operators</strong>, and click <strong>NVIDIA GPU Operator</strong>.</p></li>
<li><p>Select the <strong>ClusterPolicy</strong> tab, then click <strong>Create ClusterPolicy</strong>. The platform assigns the default name <em>gpu-cluster-policy</em>.</p></li>
<li><p>Provide name of the licensing <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> under <strong>Driver</strong> section, this should be created during pre-requsite steps above for NVIDIA vGPU. Refer to below screenshots for example and modify values accordingly.</p></li>
</ol>
<blockquote>
<div><img alt="_images/cluster_policy_vgpu_1.png" src="_images/cluster_policy_vgpu_1.png" />
</div></blockquote>
<ol class="arabic simple">
<li><p>Specify <code class="docutils literal notranslate"><span class="pre">repository</span></code> path, <code class="docutils literal notranslate"><span class="pre">image</span></code> name and NVIDIA vGPU driver <code class="docutils literal notranslate"><span class="pre">version</span></code> bundled under <strong>Driver</strong> section. If the registry is not public, please specify the <code class="docutils literal notranslate"><span class="pre">imagePullSecret</span></code> created during pre-requisite step under <strong>Driver</strong> advanced configurations section.</p></li>
</ol>
<blockquote>
<div><img alt="_images/cluster_policy_vgpu_2.png" src="_images/cluster_policy_vgpu_2.png" />
</div></blockquote>
<ol class="arabic">
<li><p>Click <strong>Create</strong>.</p>
<p>At this point, the GPU Operator proceeds and installs all the required components to set up the NVIDIA GPUs in the OpenShift 4 cluster. Wait at least 10-20 minutes before digging deeper into any form of troubleshooting because this may take a period of time to finish.</p>
</li>
<li><p>The status of the newly deployed ClusterPolicy <em>gpu-cluster-policy</em> for the NVIDIA GPU Operator changes to <code class="docutils literal notranslate"><span class="pre">State:ready</span></code> when the installation succeeds.</p></li>
</ol>
<blockquote>
<div><img alt="_images/cluster-policy-state-ready.png" src="_images/cluster-policy-state-ready.png" />
</div></blockquote>
</section>
<section id="id2">
<h3>Create the cluster policy using the CLI<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Create the ClusterPolicy:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get csv -n nvidia-gpu-operator gpu-operator-certified.v22.9.0 -ojsonpath<span class="o">={</span>.metadata.annotations.alm-examples<span class="o">}</span> <span class="p">|</span> jq .<span class="o">[</span><span class="m">0</span><span class="o">]</span> &gt; clusterpolicy.json
</pre></div>
</div>
<p>Modify clusterpolicy.json file to specify <code class="docutils literal notranslate"><span class="pre">driver.licensingConfig</span></code>, <code class="docutils literal notranslate"><span class="pre">driver.repository</span></code>, <code class="docutils literal notranslate"><span class="pre">driver.image</span></code>, <code class="docutils literal notranslate"><span class="pre">driver.version</span></code> and <code class="docutils literal notranslate"><span class="pre">driver.imagePullSecrets</span></code> created during pre-requiste steps. Below snippet is shown as an example, please change values accordingly.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="nt">&quot;driver&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;repository&quot;</span><span class="p">:</span><span class="w"> </span><span class="nt">&quot;&lt;repository-path&gt;&quot;</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;image&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;driver&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;imagePullSecrets&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;licensingConfig&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">       </span><span class="nt">&quot;configMapName&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;licensing-config&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">       </span><span class="nt">&quot;nlsEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w"></span>
<span class="w">     </span><span class="p">}</span><span class="w"></span>
<span class="w">     </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;470.82.01&quot;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc apply -f clusterpolicy.json
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">clusterpolicy.nvidia.com/gpu-cluster-policy created</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="verify-the-successful-installation-of-the-nvidia-gpu-operator">
<h2>Verify the successful installation of the NVIDIA GPU Operator<a class="headerlink" href="#verify-the-successful-installation-of-the-nvidia-gpu-operator" title="Permalink to this headline"></a></h2>
<p>Verify the successful installation of the NVIDIA GPU Operator as shown here:</p>
<ol class="arabic">
<li><p>Run the following command to view these new pods and daemonsets:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get pods,daemonset -n nvidia-gpu-operator
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                      READY   STATUS      RESTARTS   AGE</span>
<span class="go">pod/gpu-feature-discovery-c2rfm                           1/1     Running     0          6m28s</span>
<span class="go">pod/gpu-operator-84b7f5bcb9-vqds7                         1/1     Running     0          39m</span>
<span class="go">pod/nvidia-container-toolkit-daemonset-pgcrf              1/1     Running     0          6m28s</span>
<span class="go">pod/nvidia-cuda-validator-p8gv2                           0/1     Completed   0          99s</span>
<span class="go">pod/nvidia-dcgm-exporter-kv6k8                            1/1     Running     0          6m28s</span>
<span class="go">pod/nvidia-dcgm-tpsps                                     1/1     Running     0          6m28s</span>
<span class="go">pod/nvidia-device-plugin-daemonset-gbn55                  1/1     Running     0          6m28s</span>
<span class="go">pod/nvidia-device-plugin-validator-z7ltr                  0/1     Completed   0          82s</span>
<span class="go">pod/nvidia-driver-daemonset-410.84.202203290245-0-xxgdv   2/2     Running     0          6m28s</span>
<span class="go">pod/nvidia-node-status-exporter-snmsm                     1/1     Running     0          6m28s</span>
<span class="go">pod/nvidia-operator-validator-6pfk6                       1/1     Running     0          6m28s</span>

<span class="go">NAME                                                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                                                                                         AGE</span>
<span class="go">daemonset.apps/gpu-feature-discovery                           1         1         1       1            1           nvidia.com/gpu.deploy.gpu-feature-discovery=true                                                                      6m28s</span>
<span class="go">daemonset.apps/nvidia-container-toolkit-daemonset              1         1         1       1            1           nvidia.com/gpu.deploy.container-toolkit=true                                                                          6m28s</span>
<span class="go">daemonset.apps/nvidia-dcgm                                     1         1         1       1            1           nvidia.com/gpu.deploy.dcgm=true                                                                                       6m28s</span>
<span class="go">daemonset.apps/nvidia-dcgm-exporter                            1         1         1       1            1           nvidia.com/gpu.deploy.dcgm-exporter=true                                                                              6m28s</span>
<span class="go">daemonset.apps/nvidia-device-plugin-daemonset                  1         1         1       1            1           nvidia.com/gpu.deploy.device-plugin=true                                                                              6m28s</span>
<span class="go">daemonset.apps/nvidia-driver-daemonset-410.84.202203290245-0   1         1         1       1            1           feature.node.kubernetes.io/system-os_release.OSTREE_VERSION=410.84.202203290245-0,nvidia.com/gpu.deploy.driver=true   6m28s</span>
<span class="go">daemonset.apps/nvidia-mig-manager                              0         0         0       0            0           nvidia.com/gpu.deploy.mig-manager=true                                                                                6m28s</span>
<span class="go">daemonset.apps/nvidia-node-status-exporter                     1         1         1       1            1           nvidia.com/gpu.deploy.node-status-exporter=true                                                                       6m29s</span>
<span class="go">daemonset.apps/nvidia-operator-validator                       1         1         1       1            1           nvidia.com/gpu.deploy.operator-validator=true                                                                         6m28s</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">nvidia-driver-daemonset</span></code> pod runs on each worker node that contains a supported NVIDIA GPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the Driver Toolkit is active, the <code class="docutils literal notranslate"><span class="pre">DaemonSet</span></code> is named <code class="docutils literal notranslate"><span class="pre">nvidia-driver-daemonset-&lt;RHCOS-version&gt;</span></code>. Where <code class="docutils literal notranslate"><span class="pre">RHCOS-version</span></code> equals <code class="docutils literal notranslate"><span class="pre">&lt;OCP</span> <span class="pre">XY&gt;.&lt;RHEL</span> <span class="pre">XY&gt;.&lt;related</span> <span class="pre">date</span> <span class="pre">YYYYMMDDHHSS-0</span></code>.
The pods of the <code class="docutils literal notranslate"><span class="pre">DaemonSet</span></code> are named <code class="docutils literal notranslate"><span class="pre">nvidia-driver-daemonset-&lt;RHCOS-version&gt;-&lt;UUID&gt;</span></code>.</p>
</div>
</li>
</ol>
</section>
<section id="cluster-monitoring">
<h2>Cluster monitoring<a class="headerlink" href="#cluster-monitoring" title="Permalink to this headline"></a></h2>
<p>The GPU Operator generates GPU performance metrics (DCGM-export), status metrics (node-status-exporter) and node-status alerts. For OpenShift Prometheus to collect these metrics, the namespace hosting the GPU Operator must have the label <code class="docutils literal notranslate"><span class="pre">openshift.io/cluster-monitoring=true</span></code>.</p>
<p>When the GPU Operator is installed in the suggested <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code> namespace, the GPU Operator automatically enables monitoring if the <code class="docutils literal notranslate"><span class="pre">openshift.io/cluster-monitoring</span></code> label is not defined.
If the label is defined, the GPU Operator will not change its value.</p>
<p>Disable cluster monitoring in the <code class="docutils literal notranslate"><span class="pre">nvidia-gpu-operator</span></code> namespace by setting <code class="docutils literal notranslate"><span class="pre">openshift.io/cluster-monitoring=false</span></code> as shown:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc label ns/nvidia-gpu-operator openshift.io/cluster-monitoring<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</div></blockquote>
<p>If the GPU Operator is not installed in the suggested namespace, the GPU Operator will not automatically enable monitoring. Set the label manually as shown:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc label ns/<span class="nv">$NAMESPACE</span> openshift.io/cluster-monitoring<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Only do this if trusted operators are installed in this namespace.</p>
</div>
</div></blockquote>
</section>
<section id="logging">
<h2>Logging<a class="headerlink" href="#logging" title="Permalink to this headline"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">nvidia-driver-daemonset</span></code> pod has two containers.</p>
<ol class="arabic">
<li><p>Run the following to examine the logs associated with the <code class="docutils literal notranslate"><span class="pre">nvidia-driver-ctr</span></code>:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This log shows the main container waiting for the driver binary, and loading it in memory.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc logs -f nvidia-driver-daemonset-410.84.202203290245-0-xxgdv -n nvidia-gpu-operator -c nvidia-driver-ctr
</pre></div>
</div>
</li>
<li><p>Run the following to examine the logs associated with the <code class="docutils literal notranslate"><span class="pre">openshift-driver-toolkit-ctr</span></code>:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This log shows the driver being built.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc logs -f nvidia-driver-daemonset-410.84.202203290245-0-xxgdv -n nvidia-gpu-operator -c openshift-driver-toolkit-ctr
</pre></div>
</div>
</li>
</ol>
</section>
<section id="running-a-sample-gpu-application">
<span id="running-sample-app"></span><h2>Running a sample GPU Application<a class="headerlink" href="#running-a-sample-gpu-application" title="Permalink to this headline"></a></h2>
<p>Run a simple CUDA VectorAdd sample, which adds two vectors together to ensure the GPUs have bootstrapped correctly.</p>
<ol class="arabic">
<li><p>Run the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat &lt;&lt; EOF <span class="p">|</span> oc create -f -

<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: cuda-vectoradd</span>
<span class="go">spec:</span>
<span class="go"> restartPolicy: OnFailure</span>
<span class="go"> containers:</span>
<span class="go"> - name: cuda-vectoradd</span>
<span class="go">   image: &quot;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda12.5.0-ubi8&quot;</span>
<span class="go">   resources:</span>
<span class="go">     limits:</span>
<span class="go">       nvidia.com/gpu: 1</span>
<span class="go">EOF</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pod/cuda-vectoradd created</span>
</pre></div>
</div>
</li>
<li><p>Check the logs of the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc logs cuda-vectoradd
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[Vector addition of 50000 elements]</span>
<span class="go">Copy input data from the host memory to the CUDA device</span>
<span class="go">CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">Copy output data from the CUDA device to the host memory</span>
<span class="go">Test PASSED</span>
<span class="go">Done</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="getting-information-about-the-gpu">
<h2>Getting information about the GPU<a class="headerlink" href="#getting-information-about-the-gpu" title="Permalink to this headline"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> shows memory usage, GPU utilization, and the temperature of the GPU. Test the GPU access by running the popular <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command within the pod.</p>
<p>To view GPU utilization, run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> from a pod in the GPU Operator daemonset.</p>
<ol class="arabic">
<li><p>Change to the nvidia-gpu-operator project:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc project nvidia-gpu-operator
</pre></div>
</div>
</li>
<li><p>Run the following command to view these new pods:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc get pod -owide -lopenshift.driver-toolkit<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                  READY   STATUS    RESTARTS   AGE   IP            NODE                           NOMINATED NODE   READINESS GATES</span>
<span class="go">nvidia-driver-daemonset-410.84.202203290245-0-xxgdv   2/2     Running   0          23m   10.130.2.18   ip-10-0-143-147.ec2.internal   &lt;none&gt;           &lt;none&gt;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With the Pod and node name, run the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> on the correct node.</p>
</div>
</li>
<li><p>Run the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command within the pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc <span class="nb">exec</span> -it nvidia-driver-daemonset-410.84.202203290245-0-xxgdv -- nvidia-smi
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Defaulted container &quot;nvidia-driver-ctr&quot; out of: nvidia-driver-ctr, openshift-driver-toolkit-ctr, k8s-driver-manager (init)</span>
<span class="go">Mon Apr 11 15:02:23 2022</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span>
<span class="go">| N/A   33C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |</span>
<span class="go">|                               |                      |                  N/A |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
<p>Two tables are generated. The first table reflects the information about all available GPUs (the example shows one GPU). The second table provides details on the processes using the GPUs.</p>
<p>For more information describing the contents of the tables see the man page for <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>.</p>
</li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install-nfd.html" class="btn btn-neutral float-left" title="Installing the Node Feature Discovery Operator on OpenShift" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nvaie-with-ocp.html" class="btn btn-neutral float-right" title="NVIDIA AI Enterprise with OpenShift" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
<img src="_static/NVIDIA-LogoBlack.svg" class="only-light"/>
<img src="_static/NVIDIA-LogoWhite.svg" class="only-dark"/>
<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>
<p>
  Copyright &#169; 2020-2024, NVIDIA Corporation.
</p>

    <p>
      <span class="lastupdated">Last updated on Nov 21, 2024.
      </span></p>
<script type="text/javascript">if (typeof _satellite !== "undefined"){ _satellite.pageBottom();}</script>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>