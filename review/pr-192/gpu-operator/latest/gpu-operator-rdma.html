


<!DOCTYPE html>


<html data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>GPUDirect RDMA and GPUDirect Storage &#8212; NVIDIA GPU Operator</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/nvidia-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/mermaid-init.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'gpu-operator-rdma';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '../versions1.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '25.3.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <script src="_static/version.js"></script>
    <script src="_static/social-media.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Considerations when Installing with Outdated Kernels in Cluster" href="install-gpu-operator-outdated-kernels.html" />
    <link rel="prev" title="Time-Slicing GPUs in Kubernetes" href="gpu-sharing.html" />


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  <meta name="docsearch:version" content="" />
    <meta name="docbuild:last-update" content="Jun 17, 2025"/>



  <script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js" ></script>
  


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA GPU Operator - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NVIDIA GPU Operator - Home"/>
  
  
    <p class="title logo__title">NVIDIA GPU Operator</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA GPU Operator - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NVIDIA GPU Operator - Home"/>
  
  
    <p class="title logo__title">NVIDIA GPU Operator</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview.html">About the Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="upgrade.html">Upgrade</a></li>
<li class="toctree-l1"><a class="reference internal" href="uninstall.html">Uninstall</a></li>
<li class="toctree-l1"><a class="reference internal" href="platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-vgpu.html">Using NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="security.html">Security Considerations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Operator Configuration</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-sharing.html">Time-Slicing GPUs</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-outdated-kernels.html">Outdated Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom-driver-params.html">Custom GPU Driver Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="precompiled-drivers.html">Precompiled Driver Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-driver-configuration.html">GPU Driver CRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="cdi.html">Container Device Interface Support</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sandboxed Workloads</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-kubevirt.html">KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-kata.html">Kata Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-operator-confidential-containers.html">Confidential Containers and Kata</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Specialized Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-proxy.html">HTTP Proxy</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-air-gapped.html">Air-Gapped Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-gpu-operator-service-mesh.html">Service Mesh</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">CSP configurations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="amazon-eks.html">Amazon EKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="microsoft-aks.html">Azure AKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="google-gke.html">Google GKE</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    <li class="breadcrumb-item breadcrumb-home">
      <a href="https://docs.nvidia.com">NVIDIA Docs Hub</a>
    </li>
    <li class="breadcrumb-item">
      <a href="https://docs.nvidia.com/datacenter/cloud-native">Cloud Native Technologies</a>
    </li>
    <li class="breadcrumb-item">
      <a href="index.html">NVIDIA GPU Operator</a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">GPUDirect RDMA and GPUDirect Storage</li>
  </ul>
</nav></div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="gpudirect-rdma-and-gpudirect-storage">
<span id="operator-rdma"></span><h1>GPUDirect RDMA and GPUDirect Storage<a class="headerlink" href="#gpudirect-rdma-and-gpudirect-storage" title="Permalink to this headline">#</a></h1>
<section id="about-gpudirect-rdma-and-gpudirect-storage">
<h2>About GPUDirect RDMA and GPUDirect Storage<a class="headerlink" href="#about-gpudirect-rdma-and-gpudirect-storage" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html">GPUDirect RDMA</a> is a technology in NVIDIA GPUs that enables direct
data exchange between GPUs and a third-party peer device using PCI Express. The third-party devices could be network interfaces
such as NVIDIA ConnectX SmartNICs or BlueField DPUs, or video acquisition adapters.</p>
<p><a class="reference external" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html">GPUDirect Storage</a> (GDS) enables a direct data path between local or remote storage, such as NFS servers or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.
GDS performs direct memory access (DMA) transfers between GPU memory and storage.
DMA avoids a bounce buffer through the CPU.
This direct path increases system bandwidth and decreases the latency and utilization load on the CPU.</p>
<p>To support GPUDirect RDMA, userspace CUDA APIs are required.
The kernel mode support is provided by one of two approaches: DMA-BUF from the Linux kernel or the legacy <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.
NVIDIA recommends using the DMA-BUF rather than using the <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module from the GPU Driver.</p>
<p>The Operator uses GDS driver version 2.17.5 or newer.
This version and higher is only supported with the NVIDIA Open GPU Kernel module driver.
In GPU Operator v25.3.0 and later, the <code class="docutils literal notranslate"><span class="pre">driver.kernelModuleType</span></code> default is <code class="docutils literal notranslate"><span class="pre">auto</span></code>, for the supported driver versions.
This configuration allows the GPU Operator to choose the recommended driver kernel module type depending on the driver branch and the GPU devices available.
Newer driver versions will use the open kernel module by default, however to make sure you are using the open kernel module, include <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.kernelModuleType=open</span></code> command-line argument in your helm Operator install command.</p>
<p>In conjunction with the Network Operator, the GPU Operator can be used to
set up the networking related components such as network device kernel drivers and Kubernetes device plugins to enable
workloads to take advantage of GPUDirect RDMA and GPUDirect Storage.
Refer to the Network Operator <a class="reference external" href="https://docs.nvidia.com/networking/software/cloud-orchestration/index.html">documentation</a> for installation information.</p>
</section>
<section id="common-prerequisites">
<h2>Common Prerequisites<a class="headerlink" href="#common-prerequisites" title="Permalink to this headline">#</a></h2>
<p>The prerequisites for configuring GPUDirect RDMA or GPUDirect Storage depend on whether you use DMA-BUF from the Linux kernel or the legacy <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p>
<div class="pst-scrollable-table-container"><table class="colwidths-given table">
<colgroup>
<col style="width: 20%" />
<col style="width: 40%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head stub"><p>Technology</p></th>
<th class="head"><p>DMA-BUF</p></th>
<th class="head"><p>Legacy NVIDIA-peermem</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><th class="stub"><p>GPU Driver</p></th>
<td><p>An Open Kernel module driver is required.</p></td>
<td><p>Any supported driver.</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p>CUDA</p></th>
<td><p>CUDA 11.7 or higher.
The CUDA runtime is provided by the driver.</p></td>
<td><p>No minimum version.
The CUDA runtime is provided by the driver.</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>GPU</p></th>
<td><p>Turing architecture data center, Quadro RTX, and RTX GPU or higher.</p></td>
<td><p>All data center, Quadro RTX, and RTX GPU or higher.</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p>Network Device Drivers</p></th>
<td><p>MLNX_OFED or DOCA-OFED are optional.
You can use the Linux driver packages from the package manager.</p></td>
<td><p>MLNX_OFED or DOCA-OFED are required.</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>Linux Kernel</p></th>
<td><p>5.12 or higher.</p></td>
<td><p>No minimum version.</p></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>Make sure the network device drivers are installed.</p>
<p>You can use the <a class="reference external" href="https://docs.nvidia.com/networking/software/cloud-orchestration/index.html">Network Operator</a>
to manage the driver lifecycle for MLNX_OFED and DOCA-OFED drivers.</p>
<p>You can install the drivers on each host.
Refer to <a class="reference external" href="https://docs.nvidia.com/networking/software/adapter-software/index.html">Adapter Software</a>
in the networking documentation for information about the MLNX_OFED, DOCA-OFED, and Linux inbox drivers.</p>
</li>
<li><p>For installations on VMware vSphere, refer to the following additional prerequisites:</p>
<ul>
<li><p>Make sure the network interface controller and the NVIDIA GPU are in the same PCIe IO root complex.</p></li>
<li><p>Enable the following PCI options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pciPassthru.allowP2P</span> <span class="pre">=</span> <span class="pre">true</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pciPassthru.RelaxACSforP2P</span> <span class="pre">=</span> <span class="pre">true</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pciPassthru.use64bitMMIO</span> <span class="pre">=</span> <span class="pre">true</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pciPassthru.64bitMMIOSizeGB</span> <span class="pre">=</span> <span class="pre">128</span></code></p></li>
</ul>
<p>For information about configuring the settings, refer to the
<a class="reference external" href="https://core.vmware.com/resource/deploy-ai-ready-vsphere-7#vm-settings-A">Deploy an AI-Ready Enterprise Platform on vSphere 7</a>
document from VMWare.</p>
</li>
</ul>
</li>
</ul>
</section>
<section id="configuring-gpudirect-rdma">
<h2>Configuring GPUDirect RDMA<a class="headerlink" href="#configuring-gpudirect-rdma" title="Permalink to this headline">#</a></h2>
<section id="platform-support">
<h3>Platform Support<a class="headerlink" href="#platform-support" title="Permalink to this headline">#</a></h3>
<p>The following platforms are supported for GPUDirect with RDMA:</p>
<ul class="simple">
<li><p>Kubernetes on bare metal and on vSphere VMs with GPU passthrough and vGPU.</p></li>
<li><p>VMware vSphere with Tanzu.</p></li>
<li><p>For Red Hat OpenShift Container Platform on bare metal and on vSphere VMs with GPU passthrough and vGPU configurations,
refer to <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/nvaie-with-ocp.html#nvaie-ocp" title="(in NVIDIA GPU Operator on Red Hat OpenShift Container Platform)"><span class="xref std std-ref">NVIDIA AI Enterprise with OpenShift</span></a>.</p></li>
</ul>
<p>For information about the supported versions, refer to <a class="reference internal" href="platform-support.html#support-for-gpudirect-rdma"><span class="std std-ref">Support for GPUDirect RDMA</span></a> on the platform support page.</p>
</section>
<section id="installing-the-gpu-operator-and-enabling-gpudirect-rdma">
<h3>Installing the GPU Operator and Enabling GPUDirect RDMA<a class="headerlink" href="#installing-the-gpu-operator-and-enabling-gpudirect-rdma" title="Permalink to this headline">#</a></h3>
<p>To use DMA-BUF and network device drivers that are installed by the Network Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --version<span class="o">=</span>v25.3.1 <span class="se">\</span>
</pre></div>
</div>
<p>To use DMA-BUF and network device drivers that are installed on the host:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --version<span class="o">=</span>v25.3.1 <span class="se">\</span>
     --set driver.rdma.useHostMofed<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<p>To use the legacy <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module instead of DMA-BUF, add <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.rdma.enabled=true</span></code> to either of the preceding commands.
Add <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.kernelModuleType=open</span></code> if you are using a driver version from a branch earlier than R570.</p>
</section>
<section id="verifying-the-installation-of-gpudirect-with-rdma">
<h3>Verifying the Installation of GPUDirect with RDMA<a class="headerlink" href="#verifying-the-installation-of-gpudirect-with-rdma" title="Permalink to this headline">#</a></h3>
<p>During the installation, the NVIDIA driver daemon set runs an <cite>init container</cite> to wait on the network device kernel drivers to be ready.
This init container checks for Mellanox NICs on the node and ensures that the necessary kernel symbols are exported by the kernel drivers.</p>
<p>If you were required to use the <code class="docutils literal notranslate"><span class="pre">driver.rdma.enabled=true</span></code> argument when you installed the Operator, the nvidia-peermem-ctr container is started inside each driver pod after the verification.</p>
<ol class="arabic">
<li><p>Confirm that the pod template for the driver daemon set includes the mofed-validation init container and
the nvidia-driver-ctr containers:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl describe ds -n gpu-operator nvidia-driver-daemonset
</pre></div>
</div>
<p><em>Example Output</em></p>
<p>The following partial output omits the init containers and containers that are common to all installations.</p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">...</span>
<span class="go"> Init Containers:</span>
<span class="go">  mofed-validation:</span>
<span class="go">  Container ID:  containerd://5a36c66b43f676df616e25ba7ae0c81aeaa517308f28ec44e474b2f699218de3</span>
<span class="go">  Image:         nvcr.io/nvidia/cloud-native/gpu-operator-validator:v1.8.1</span>
<span class="go">  Image ID:      nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:7a70e95fd19c3425cd4394f4b47bbf2119a70bd22d67d72e485b4d730853262c</span>
<span class="go">...</span>
<span class="go"> Containers:</span>
<span class="go">  nvidia-driver-ctr:</span>
<span class="go">  Container ID:  containerd://199a760946c55c3d7254fa0ebe6a6557dd231179057d4909e26c0e6aec49ab0f</span>
<span class="go">  Image:         nvcr.io/nvaie/vgpu-guest-driver:470.63.01-ubuntu20.04</span>
<span class="go">  Image ID:      nvcr.io/nvaie/vgpu-guest-driver@sha256:a1b7d2c8e1bad9bb72d257ddfc5cec341e790901e7574ba2c32acaddaaa94625</span>
<span class="go">...</span>
<span class="go">  nvidia-peermem-ctr:</span>
<span class="go">  Container ID:  containerd://0742d86f6017bf0c304b549ebd8caad58084a4185a1225b2c9a7f5c4a171054d</span>
<span class="go">  Image:         nvcr.io/nvaie/vgpu-guest-driver:470.63.01-ubuntu20.04</span>
<span class="go">  Image ID:      nvcr.io/nvaie/vgpu-guest-driver@sha256:a1b7d2c8e1bad9bb72d257ddfc5cec341e790901e7574ba2c32acaddaaa94625</span>
<span class="go">...</span>
</pre></div>
</div>
<p>The nvidia-peermem-ctr container is present only if you were required to specify the <code class="docutils literal notranslate"><span class="pre">driver.rdma.enabled=true</span></code> argument when you installed the Operator.</p>
</li>
<li><p>Legacy only: Confirm that the nvidia-peermem-ctr container successfully loaded the nvidia-peermem kernel module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl logs -n gpu-operator ds/nvidia-driver-daemonset -c nvidia-peermem-ctr
</pre></div>
</div>
<p>Alternatively, run <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">logs</span> <span class="pre">-n</span> <span class="pre">gpu-operator</span> <span class="pre">nvidia-driver-daemonset-xxxxx</span> <span class="pre">-c</span> <span class="pre">nvidia-peermem-ctr</span></code> for each pod in the daemonset.</p>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">waiting for mellanox ofed and nvidia drivers to be installed</span>
<span class="go">waiting for mellanox ofed and nvidia drivers to be installed</span>
<span class="go">successfully loaded nvidia-peermem module</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="verifying-the-installation-by-performing-a-data-transfer">
<h3>Verifying the Installation by Performing a Data Transfer<a class="headerlink" href="#verifying-the-installation-by-performing-a-data-transfer" title="Permalink to this headline">#</a></h3>
<p>You can perform the following steps to verify that GPUDirect with RDMA is configured
correctly and that pods can perform RDMA data transfers.</p>
<ol class="arabic">
<li><p>Get the network interface name of the InfiniBand device on the host:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl <span class="nb">exec</span> -it -n network-operator mofed-ubuntu22.04-ds-xxxxx -- ibdev2netdev
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">mlx5_0 port 1 ==&gt; ens64np1 (Up)</span>
</pre></div>
</div>
</li>
<li><p>Configure a secondary network on the device using a macvlan network attachment:</p>
<ul>
<li><p>Create a file, such as <code class="docutils literal notranslate"><span class="pre">demo-macvlannetwork.yaml</span></code>, with contents like the following example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mellanox.com/v1alpha1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MacvlanNetwork</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">demo-macvlannetwork</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">networkNamespace</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;default&quot;</span><span class="w"></span>
<span class="hll"><span class="nt">master</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;ens64np1&quot;</span><span class="w"></span>
</span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;bridge&quot;</span><span class="w"></span>
<span class="nt">mtu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1500</span><span class="w"></span>
<span class="nt">ipam</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span><span class="w"></span>
<span class="w">  </span><span class="no">{</span><span class="w"></span>
<span class="w">    </span><span class="no">&quot;type&quot;: &quot;whereabouts&quot;,</span><span class="w"></span>
<span class="w">    </span><span class="no">&quot;range&quot;: &quot;192.168.2.225/28&quot;,</span><span class="w"></span>
<span class="w">    </span><span class="no">&quot;exclude&quot;: [</span><span class="w"></span>
<span class="w">      </span><span class="no">&quot;192.168.2.229/30&quot;,</span><span class="w"></span>
<span class="w">      </span><span class="no">&quot;192.168.2.236/32&quot;</span><span class="w"></span>
<span class="w">    </span><span class="no">]</span><span class="w"></span>
<span class="w">  </span><span class="no">}</span><span class="w"></span>
</pre></div>
</div>
<p>Replace <code class="docutils literal notranslate"><span class="pre">ens64np1</span></code> with the the network interface name reported by the <code class="docutils literal notranslate"><span class="pre">ibdev2netdev</span></code> command
from the preceding step.</p>
</li>
<li><p>Apply the manifest:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f demo-macvlannetwork.yaml
</pre></div>
</div>
</li>
<li><p>Confirm that the additional network is ready:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get macvlannetworks demo-macvlannetwork
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                  STATUS   AGE</span>
<span class="go">demo-macvlannetwork   ready    2023-03-10T18:22:28Z</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Start two pods that run the <code class="docutils literal notranslate"><span class="pre">mellanox/cuda-perftest</span></code> container on two different nodes in the cluster.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="2beacb50-6dd2-479d-8b42-c150d3d7e9cd" name="df95034a-dfc6-437b-94fc-79f1219f2b38" type="radio">
</input><label class="sd-tab-label" for="2beacb50-6dd2-479d-8b42-c150d3d7e9cd">
demo-pod-1</label><div class="sd-tab-content docutils">
<ul>
<li><p>Create a file, such as <code class="docutils literal notranslate"><span class="pre">demo-pod-1.yaml</span></code>, for the first pod with contents like the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pod</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">demo-pod-1</span><span class="w"></span>
</span><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">k8s.v1.cni.cncf.io/networks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">demo-macvlannetwork</span><span class="w"></span>
<span class="w">    </span><span class="c1"># If a network with static IPAM is used replace network annotation with the below.</span><span class="w"></span>
<span class="w">    </span><span class="c1"># k8s.v1.cni.cncf.io/networks: &#39;[</span><span class="w"></span>
<span class="w">    </span><span class="c1">#   { &quot;name&quot;: &quot;rdma-net&quot;,</span><span class="w"></span>
<span class="w">    </span><span class="c1">#     &quot;ips&quot;: [&quot;192.168.111.101/24&quot;],</span><span class="w"></span>
<span class="w">    </span><span class="c1">#     &quot;gateway&quot;: [&quot;192.168.111.1&quot;]</span><span class="w"></span>
<span class="w">    </span><span class="c1">#   }</span><span class="w"></span>
<span class="w">    </span><span class="c1"># ]&#39;</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">nodeSelector</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="c1"># Note: Replace hostname or remove selector altogether</span><span class="w"></span>
<span class="hll"><span class="w">    </span><span class="nt">kubernetes.io/hostname</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvnode1</span><span class="w"></span>
</span><span class="w">  </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OnFailure</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mellanox/cuda-perftest</span><span class="w"></span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rdma-gpu-test-ctr</span><span class="w"></span>
<span class="w">    </span><span class="nt">securityContext</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">capabilities</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">add</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">&quot;IPC_LOCK&quot;</span><span class="w"> </span><span class="p p-Indicator">]</span><span class="w"></span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">        </span><span class="nt">rdma/rdma_shared_device_a</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">        </span><span class="nt">rdma/rdma_shared_device_a</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Apply the manifest:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f demo-pod-1.yaml
</pre></div>
</div>
</li>
</ul>
</div>
<input id="14556950-dec1-4879-bb51-96635afa089d" name="df95034a-dfc6-437b-94fc-79f1219f2b38" type="radio">
</input><label class="sd-tab-label" for="14556950-dec1-4879-bb51-96635afa089d">
demo-pod-2</label><div class="sd-tab-content docutils">
<ul>
<li><p>Create a file, such as <code class="docutils literal notranslate"><span class="pre">demo-pod-2.yaml</span></code>, for the second pod with contents like the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pod</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">demo-pod-2</span><span class="w"></span>
</span><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">k8s.v1.cni.cncf.io/networks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">demo-macvlannetwork</span><span class="w"></span>
<span class="w">    </span><span class="c1"># If a network with static IPAM is used replace network annotation with the below.</span><span class="w"></span>
<span class="w">    </span><span class="c1"># k8s.v1.cni.cncf.io/networks: &#39;[</span><span class="w"></span>
<span class="w">    </span><span class="c1">#   { &quot;name&quot;: &quot;rdma-net&quot;,</span><span class="w"></span>
<span class="w">    </span><span class="c1">#     &quot;ips&quot;: [&quot;192.168.111.101/24&quot;],</span><span class="w"></span>
<span class="w">    </span><span class="c1">#     &quot;gateway&quot;: [&quot;192.168.111.1&quot;]</span><span class="w"></span>
<span class="w">    </span><span class="c1">#   }</span><span class="w"></span>
<span class="w">    </span><span class="c1"># ]&#39;</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">nodeSelector</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="c1"># Note: Replace hostname or remove selector altogether</span><span class="w"></span>
<span class="hll"><span class="w">    </span><span class="nt">kubernetes.io/hostname</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvnode2</span><span class="w"></span>
</span><span class="w">  </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OnFailure</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mellanox/cuda-perftest</span><span class="w"></span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rdma-gpu-test-ctr</span><span class="w"></span>
<span class="w">    </span><span class="nt">securityContext</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">capabilities</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">add</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">&quot;IPC_LOCK&quot;</span><span class="w"> </span><span class="p p-Indicator">]</span><span class="w"></span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">        </span><span class="nt">rdma/rdma_shared_device_a</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="w">        </span><span class="nt">rdma/rdma_shared_device_a</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Apply the manifest:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f demo-pod-2.yaml
</pre></div>
</div>
</li>
</ul>
</div>
</div>
</li>
<li><p>Get the IP addresses of the pods:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods -o wide
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">NAME         READY   STATUS    RESTARTS   AGE    IP              NODE      NOMINATED NODE   READINESS GATES</span>
<span class="go">demo-pod-1   1/1     Running   0          3d4h   192.168.38.90   nvnode1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">demo-pod-2   1/1     Running   0          3d4h   192.168.47.89   nvnode2   &lt;none&gt;           &lt;none&gt;</span>
</pre></div>
</div>
</li>
<li><p>From one terminal, open a shell in the container on the first pod and start the performance test server:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl <span class="nb">exec</span> -it demo-pod-1 -- ib_write_bw --use_cuda<span class="o">=</span><span class="m">0</span> --use_cuda_dmabuf <span class="se">\</span>
    -d mlx5_0 -a -F --report_gbits -q <span class="m">1</span>
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">************************************</span>
<span class="go">* Waiting for client to connect... *</span>
<span class="go">************************************</span>
</pre></div>
</div>
</li>
<li><p>From another terminal, open a shell in the container on the second pod and run the performance client:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl <span class="nb">exec</span> -it demo-pod-2 -- ib_write_bw -n <span class="m">5000</span> --use_cuda<span class="o">=</span><span class="m">0</span> --use_cuda_dmabuf <span class="se">\</span>
    -d mlx5_0 -a -F --report_gbits -q <span class="m">1</span> <span class="m">192</span>.168.38.90
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go"> ---------------------------------------------------------------------------------------</span>
<span class="go">                    RDMA_Write BW Test</span>
<span class="go"> Dual-port       : OFF          Device         : mlx5_0</span>
<span class="go"> Number of qps   : 1            Transport type : IB</span>
<span class="go"> Connection type : RC           Using SRQ      : OFF</span>
<span class="go"> PCIe relax order: ON</span>
<span class="go"> ibv_wr* API     : ON</span>
<span class="go"> TX depth        : 128</span>
<span class="go"> CQ Moderation   : 100</span>
<span class="go"> Mtu             : 1024[B]</span>
<span class="go"> Link type       : Ethernet</span>
<span class="go"> GID index       : 5</span>
<span class="go"> Max inline data : 0[B]</span>
<span class="go"> rdma_cm QPs     : OFF</span>
<span class="go"> Data ex. method : Ethernet</span>
<span class="go">---------------------------------------------------------------------------------------</span>
<span class="go"> local address: LID 0000 QPN 0x01ac PSN 0xc76db1 RKey 0x23beb2 VAddr 0x007f26a2c8b000</span>
<span class="go"> GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:02:226</span>
<span class="go"> remote address: LID 0000 QPN 0x01a9 PSN 0x2f722 RKey 0x23beaf VAddr 0x007f820b24f000</span>
<span class="go"> GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:02:225</span>
<span class="go">---------------------------------------------------------------------------------------</span>
<span class="go"> #bytes     #iterations    BW peak[Gb/sec]    BW average[Gb/sec]   MsgRate[Mpps]</span>
<span class="go"> 2          5000             0.11               0.11               6.897101</span>
<span class="go"> 4          5000             0.22               0.22               6.995646</span>
<span class="go"> 8          5000             0.45               0.45               7.014752</span>
<span class="go"> 16         5000             0.90               0.90               7.017509</span>
<span class="go"> 32         5000             1.80               1.80               7.020162</span>
<span class="go"> 64         5000             3.59               3.59               7.007110</span>
<span class="go"> 128        5000             7.19               7.18               7.009540</span>
<span class="go"> 256        5000             15.06              14.98              7.313517</span>
<span class="go"> 512        5000             30.04              29.73              7.259329</span>
<span class="go"> 1024       5000             59.65              58.81              7.178529</span>
<span class="go"> 2048       5000             91.53              91.47              5.582931</span>
<span class="go"> 4096       5000             92.13              92.06              2.809574</span>
<span class="go"> 8192       5000             92.35              92.31              1.408535</span>
<span class="go"> 16384      5000             92.46              92.46              0.705381</span>
<span class="go"> 32768      5000             92.36              92.35              0.352302</span>
<span class="go"> 65536      5000             92.39              92.38              0.176196</span>
<span class="go"> 131072     5000             92.42              92.41              0.088131</span>
<span class="go"> 262144     5000             92.45              92.44              0.044080</span>
<span class="go"> 524288     5000             92.42              92.42              0.022034</span>
<span class="go"> 1048576    5000             92.40              92.40              0.011015</span>
<span class="go"> 2097152    5000             92.40              92.39              0.005507</span>
<span class="go"> 4194304    5000             92.40              92.39              0.002753</span>
<span class="go"> 8388608    5000             92.39              92.39              0.001377</span>
<span class="go">---------------------------------------------------------------------------------------</span>
</pre></div>
</div>
<p>The command output indicates that the data transfer rate was approximately 92 Gbps.</p>
</li>
<li><p>Delete the pods:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete -f demo-pod-1.yaml -f demo-pod-2.yaml
</pre></div>
</div>
</li>
<li><p>Delete the secondary network:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl delete -f demo-macvlannetworks.yaml
</pre></div>
</div>
</li>
</ol>
</section>
</section>
<section id="using-gpudirect-storage">
<h2>Using GPUDirect Storage<a class="headerlink" href="#using-gpudirect-storage" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3>Platform Support<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>See <a class="reference internal" href="platform-support.html#support-for-gpudirect-storage"><span class="std std-ref">Support for GPUDirect Storage</span></a> on the platform support page.</p>
</section>
<section id="installing-the-gpu-operator-and-enabling-gpudirect-storage">
<h3>Installing the GPU Operator and Enabling GPUDirect Storage<a class="headerlink" href="#installing-the-gpu-operator-and-enabling-gpudirect-storage" title="Permalink to this headline">#</a></h3>
<p>The following section is applicable to the following configurations and describe how to deploy the GPU Operator using the Helm Chart:</p>
<ul class="simple">
<li><p>Kubernetes on bare metal and on vSphere VMs with GPU passthrough and vGPU.</p></li>
</ul>
<p>Starting with v22.9.1, the GPU Operator provides an option to load the <code class="docutils literal notranslate"><span class="pre">nvidia-fs</span></code> kernel module during the bootstrap of the NVIDIA driver daemon set.
Starting with v23.9.1, the GPU Operator deploys a version of GDS that requires using the NVIDIA Open Kernel module driver.</p>
<p>The following sample command applies to clusters that use the Network Operator to install the network device kernel drivers.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install --wait --generate-name <span class="se">\</span>
     -n gpu-operator --create-namespace <span class="se">\</span>
     nvidia/gpu-operator <span class="se">\</span>
     --version<span class="o">=</span>v25.3.1 <span class="se">\</span>
     --set gds.enabled<span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<p>Add <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.rdma.enabled=true</span></code> to the command to use the legacy <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p>
<p>Add <code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">driver.kernelModuleType=open</span></code> if you are using a driver version from a branch earlier than R570.</p>
</section>
<section id="verification">
<h3>Verification<a class="headerlink" href="#verification" title="Permalink to this headline">#</a></h3>
<p>During the installation, an init container is used with the driver daemon set to wait on the network device kernel drivers to be ready.
This init container checks for Mellanox NICs on the node and ensures that the necessary kernel symbols are exported by the kernel drivers.
After the verification completes, the nvidia-fs-ctr container starts inside the driver pods.</p>
<p>If you were required to use the <code class="docutils literal notranslate"><span class="pre">driver.rdma.enabled=true</span></code> argument when you installed the Operator, the nvidia-peermem-ctr container is started inside each driver pod after the verification.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pod -n gpu-operator
</pre></div>
</div>
<p><em>Example Output</em></p>
<div class="highlight-output notranslate"><div class="highlight"><pre><span></span><span class="go">gpu-operator   gpu-feature-discovery-pktzg                                       1/1     Running     0          11m</span>
<span class="go">gpu-operator   gpu-operator-1672257888-node-feature-discovery-master-7ccb7txmc   1/1     Running     0          12m</span>
<span class="go">gpu-operator   gpu-operator-1672257888-node-feature-discovery-worker-bqhrl       1/1     Running     0          11m</span>
<span class="go">gpu-operator   gpu-operator-6f64c86bc-zjqdh                                      1/1     Running     0          12m</span>
<span class="go">gpu-operator   nvidia-container-toolkit-daemonset-rgwqg                          1/1     Running     0          11m</span>
<span class="go">gpu-operator   nvidia-cuda-validator-8whvt                                       0/1     Completed   0          8m50s</span>
<span class="go">gpu-operator   nvidia-dcgm-exporter-pt9q9                                        1/1     Running     0          11m</span>
<span class="go">gpu-operator   nvidia-device-plugin-daemonset-472fc                              1/1     Running     0          11m</span>
<span class="go">gpu-operator   nvidia-device-plugin-validator-29nhc                              0/1     Completed   0          8m34s</span>
<span class="go">gpu-operator   nvidia-driver-daemonset-j9vw6                                     3/3     Running     0          12m</span>
<span class="go">gpu-operator   nvidia-mig-manager-mtjcw                                          1/1     Running     0          7m35s</span>
<span class="go">gpu-operator   nvidia-operator-validator-b8nz2                                   1/1     Running     0          11m</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl describe pod -n gpu-operator nvidia-driver-daemonset-xxxx
<span class="go">&lt;snip&gt;</span>
<span class="go"> Init Containers:</span>
<span class="go">  mofed-validation:</span>
<span class="go">   Container ID:  containerd://a31a8c16ce7596073fef7cb106da94c452fdff111879e7fc3ec58b9cef83856a</span>
<span class="go">   Image:         nvcr.io/nvidia/cloud-native/gpu-operator-validator:v22.9.1</span>
<span class="go">   Image ID:      nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:18c9ea88ae06d479e6657b8a4126a8ee3f4300a40c16ddc29fb7ab3763d46005</span>

<span class="go"> &lt;snip&gt;</span>
<span class="go"> Containers:</span>
<span class="go">  nvidia-driver-ctr:</span>
<span class="go">   Container ID:  containerd://7cf162e4ee4af865c0be2023d61fbbf68c828d396207e7eab2506f9c2a5238a4</span>
<span class="go">   Image:         nvcr.io/nvidia/driver:525.60.13-ubuntu20.04</span>
<span class="go">   Image ID:      nvcr.io/nvidia/driver@sha256:0ee0c585fa720f177734b3295a073f402d75986c1fe018ae68bd73fe9c21b8d8</span>


<span class="go">  &lt;snip&gt;</span>
<span class="go">  nvidia-peermem-ctr:</span>
<span class="go">   Container ID:  containerd://5c71c9f8ccb719728a0503500abecfb5423e8088f474d686ee34b5fe3746c28e</span>
<span class="go">   Image:         nvcr.io/nvidia/driver:525.60.13-ubuntu20.04</span>
<span class="go">   Image ID:      nvcr.io/nvidia/driver@sha256:0ee0c585fa720f177734b3295a073f402d75986c1fe018ae68bd73fe9c21b8d8</span>

<span class="go">  &lt;snip&gt;</span>
<span class="go">  nvidia-fs-ctr:</span>
<span class="go">   Container ID:  containerd://f5c597d59e1cf8747aa20b8c229a6f6edd3ed588b9d24860209ba0cc009c0850</span>
<span class="go">   Image:         nvcr.io/nvidia/cloud-native/nvidia-fs:2.14.13-ubuntu20.04</span>
<span class="go">   Image ID:      nvcr.io/nvidia/cloud-native/nvidia-fs@sha256:109485365f68caeaee1edee0f3f4d722fe5b5d7071811fc81c630c8a840b847b</span>

<span class="go"> &lt;snip&gt;</span>
</pre></div>
</div>
<p>Lastly, verify that NVIDIA kernel modules are loaded on the worker node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>lsmod <span class="p">|</span> grep nvidia

<span class="go">nvidia_fs             245760  0</span>
<span class="go">nvidia_peermem         16384  0</span>
<span class="go">nvidia_modeset       1159168  0</span>
<span class="go">nvidia_uvm           1048576  0</span>
<span class="go">nvidia              39059456  115 nvidia_uvm,nvidia_modeset</span>
<span class="go">ib_core               319488  9 rdma_cm,ib_ipoib,iw_cm,ib_umad,rdma_ucm,ib_uverbs,mlx5_ib,ib_cm</span>
<span class="go">drm                   491520  6 drm_kms_helper,drm_vram_helper,nvidia,mgag200,ttm</span>
</pre></div>
</div>
</section>
</section>
<section id="related-information">
<h2>Related Information<a class="headerlink" href="#related-information" title="Permalink to this headline">#</a></h2>
<p>Refer to the following resources for more information:</p>
<blockquote>
<div><ul class="simple">
<li><p>GPUDirect RDMA: <a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html">https://docs.nvidia.com/cuda/gpudirect-rdma/index.html</a></p></li>
<li><p>NVIDIA Network Operator: <a class="github reference external" href="https://github.com/Mellanox/network-operator">Mellanox/network-operator</a></p></li>
<li><p>Blog post on deploying the Network Operator: <a class="reference external" href="https://developer.nvidia.com/blog/deploying-gpudirect-rdma-on-egx-stack-with-the-network-operator/">https://developer.nvidia.com/blog/deploying-gpudirect-rdma-on-egx-stack-with-the-network-operator/</a></p></li>
</ul>
</div></blockquote>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="gpu-sharing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Time-Slicing GPUs in Kubernetes</p>
      </div>
    </a>
    <a class="right-next"
       href="install-gpu-operator-outdated-kernels.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Considerations when Installing with Outdated Kernels in Cluster</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-gpudirect-rdma-and-gpudirect-storage">About GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-prerequisites">Common Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuring-gpudirect-rdma">Configuring GPUDirect RDMA</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#platform-support">Platform Support</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#installing-the-gpu-operator-and-enabling-gpudirect-rdma">Installing the GPU Operator and Enabling GPUDirect RDMA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#verifying-the-installation-of-gpudirect-with-rdma">Verifying the Installation of GPUDirect with RDMA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#verifying-the-installation-by-performing-a-data-transfer">Verifying the Installation by Performing a Data Transfer</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-gpudirect-storage">Using GPUDirect Storage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Platform Support</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#installing-the-gpu-operator-and-enabling-gpudirect-storage">Installing the GPU Operator and Enabling GPUDirect Storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#verification">Verification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#related-information">Related Information</a></li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Manage My Privacy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/preferences/start/">Do Not Sell or Share My Data</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2020-2025, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>

  <script type="text/javascript">if (typeof _satellite !== "undefined") {_satellite.pageBottom();}</script>
  


  </body>
</html>